{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is HTML\n",
      "Listening...\n",
      "listening energy HTML is a documentary language which is used to write\n",
      "Recorded\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "print(\"what is HTML\")\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Capture audio from the microphone\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    # Adjust for ambient noise for better recognition\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "    timeout = 5 \n",
    "    audio = recognizer.listen(source, timeout=timeout)\n",
    "\n",
    "# Process the captured audio after timeout\n",
    "try:\n",
    "    # Convert speech to text\n",
    "    user_input = recognizer.recognize_google(audio)\n",
    "    print(user_input)\n",
    "    print(\"Recorded\")\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand the audio.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between string 1 and string 2 using Sentence Transformers: 94.1352128982544%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "expected_answer = \"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.\"\n",
    "\n",
    "# Creating an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Combining the strings into a list\n",
    "corpus = [user_input, expected_answer]\n",
    "\n",
    "# Fitting the vectorizer on the corpus and transforming the strings\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Encode the sentences into Bag-of-Words representations\n",
    "bow_user_input = X.toarray()[0]\n",
    "bow_expected_answer = X.toarray()[1]\n",
    "\n",
    "model = SentenceTransformer('stsb-roberta-base')\n",
    "\n",
    "# Convert BoW arrays to string representations\n",
    "bow_str1 = ' '.join([str(elem) for elem in bow_user_input])\n",
    "bow_str2 = ' '.join([str(elem) for elem in bow_expected_answer])\n",
    "\n",
    "# Encode the BoW representations as if they were sentences\n",
    "bow_embeddings = model.encode([bow_str1, bow_str2], convert_to_tensor=True)\n",
    "\n",
    "# Compute similarity between sentence embeddings\n",
    "sbert_similarity = float(util.pytorch_cos_sim(bow_embeddings[0:1], bow_embeddings[1:2])[0][0])\n",
    "\n",
    "print(f\"Cosine Similarity between string 1 and string 2 using Sentence Transformers: {sbert_similarity * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time out which is a very good timing\n",
      "The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.\n",
      "Cosine Similarity between string 1 and string 2 using Word2Vec: 76.04469656944275%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "expected_answer = \"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.\"\n",
    "print(user_input)\n",
    "print(expected_answer)\n",
    "# Creating an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Combining the strings into a list\n",
    "corpus = [user_input, expected_answer]\n",
    "\n",
    "# Fitting the vectorizer on the corpus and transforming the strings\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Encode the sentences into Bag-of-Words representations\n",
    "bow_user_input = X.toarray()[0]\n",
    "bow_expected_answer = X.toarray()[1]\n",
    "\n",
    "# Convert BoW arrays to string representations\n",
    "bow_str1 = ' '.join([str(elem) for elem in bow_user_input])\n",
    "bow_str2 = ' '.join([str(elem) for elem in bow_expected_answer])\n",
    "\n",
    "# Tokenize the bag-of-words representations\n",
    "tokenized_bow_str1 = word_tokenize(bow_str1)\n",
    "tokenized_bow_str2 = word_tokenize(bow_str2)\n",
    "\n",
    "# Create and train a Word2Vec model\n",
    "sentences = [tokenized_bow_str1, tokenized_bow_str2]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Encode the BoW representations as Word2Vec vectors\n",
    "word2vec_user_input = np.mean([word2vec_model.wv[word] for word in tokenized_bow_str1], axis=0)\n",
    "word2vec_expected_answer = np.mean([word2vec_model.wv[word] for word in tokenized_bow_str2], axis=0)\n",
    "\n",
    "# Compute similarity between Word2Vec representations\n",
    "word2vec_similarity = np.dot(word2vec_user_input, word2vec_expected_answer) / (\n",
    "    np.linalg.norm(word2vec_user_input) * np.linalg.norm(word2vec_expected_answer)\n",
    ")\n",
    "\n",
    "print(f\"Cosine Similarity between string 1 and string 2 using Word2Vec: {word2vec_similarity * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity using Sentence Transformers: 26.316064596176147%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "expected_answer = \"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.\"\n",
    "\n",
    "# Create BoW representations\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = [user_input, expected_answer]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "bow_user_input = X.toarray()[0]\n",
    "bow_expected_answer = X.toarray()[1]\n",
    "\n",
    "# Calculate similarity using BoW representations\n",
    "bow_similarity = cosine_similarity([bow_user_input], [bow_expected_answer])[0][0] * 100\n",
    "# print(f\"Cosine Similarity using BoW: {bow_similarity}%\")\n",
    "\n",
    "model = SentenceTransformer('stsb-roberta-base')\n",
    "sentence_embeddings = model.encode(corpus)\n",
    "\n",
    "# Calculate similarity using sentence embeddings\n",
    "sbert_similarity = cosine_similarity([sentence_embeddings[0]], [sentence_embeddings[1]])[0][0] * 100\n",
    "print(f\"Cosine Similarity using Sentence Transformers: {sbert_similarity}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
